{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrMgPkLDDV/2pibNvsI7CL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Miguel1897/01-Tarea-Repaso-ReactJs/blob/master/DeteccionEnfermedades.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importación de Librerías\n",
        "\n"
      ],
      "metadata": {
        "id": "hFrIjyhpvrkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# librerías necesarias\n",
        "!pip install -q kaggle\n",
        "!pip install torch torchvision\n",
        "\n",
        "# Importa las librerías\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaRVGIuVvz6B",
        "outputId": "daf98879-79b4-4e65-ef45-b90cb1f45689"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuración de la API de Kaggle y Descarga del Dataset\n"
      ],
      "metadata": {
        "id": "Iz0cErME9Mbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configura el archivo de autenticación kaggle.json\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp /content/kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Descarga el dataset desde Kaggle\n",
        "!kaggle datasets download -d kanishk3813/pathogen-dataset --unzip\n",
        "\n",
        "# Verifica la ubicación del dataset descargado\n",
        "!ls /content\n",
        "\n",
        "# Ajusta las rutas para cargar el dataset en PyTorch\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "\n",
        "# Define la ruta del directorio según el nombre de la carpeta descomprimida\n",
        "dataset_dir = '/content/pathogen-dataset'  # Cambia esto si el nombre de la carpeta es diferente\n",
        "\n",
        "# Transforma las imágenes\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dn_zV1OK9-RP",
        "outputId": "43ff5a8e-971b-473f-d03e-3098baf9a0da"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/kanishk3813/pathogen-dataset\n",
            "License(s): apache-2.0\n",
            "Downloading pathogen-dataset.zip to /content\n",
            " 99% 1.41G/1.43G [00:14<00:00, 109MB/s]\n",
            "100% 1.43G/1.43G [00:14<00:00, 108MB/s]\n",
            "kaggle.json  pathogen  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparación del Dataset"
      ],
      "metadata": {
        "id": "ZZFeNTXT-Cip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "import os\n",
        "\n",
        "# Especifica la ruta del dataset descargado\n",
        "dataset_dir = '/content/pathogen'  # Ruta donde están las carpetas de clases\n",
        "\n",
        "# Define las transformaciones para las imágenes\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),  # Redimensionar las imágenes a 128x128\n",
        "    transforms.ToTensor()  # Convertir las imágenes a tensores\n",
        "])\n",
        "\n",
        "# Cargar el dataset completo con todas las clases\n",
        "dataset = datasets.ImageFolder(dataset_dir, transform=transform)\n",
        "\n",
        "# Verificar las clases detectadas en el dataset\n",
        "print(\"Clases:\", dataset.classes)\n",
        "\n",
        "# Dividir el dataset en entrenamiento y validación (80% entrenamiento, 20% validación)\n",
        "train_size = int(0.8 * len(dataset))  # 80% para entrenamiento\n",
        "valid_size = len(dataset) - train_size  # El resto para validación\n",
        "\n",
        "# Dividir el dataset en dos\n",
        "train_data, valid_data = random_split(dataset, [train_size, valid_size])\n",
        "\n",
        "# Crear los DataLoaders para entrenamiento y validación\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_data, batch_size=32)\n",
        "\n",
        "# Verificar la cantidad de muestras en los DataLoaders\n",
        "print(f'Tamaño del conjunto de entrenamiento: {len(train_data)}')\n",
        "print(f'Tamaño del conjunto de validación: {len(valid_data)}')\n",
        "\n",
        "# Verificar algunas clases\n",
        "print(f'Primeras clases de entrenamiento: {train_data.indices[:5]}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtOrVhZ3-Eau",
        "outputId": "53239c81-2463-4f65-b78e-e320c3a490df"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clases: ['Bacteria', 'Fungi', 'Healthy', 'Pests', 'Virus']\n",
            "Tamaño del conjunto de entrenamiento: 31997\n",
            "Tamaño del conjunto de validación: 8000\n",
            "Primeras clases de entrenamiento: [33078, 31157, 17748, 22576, 1109]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición del Modelo CNN"
      ],
      "metadata": {
        "id": "QS_53sFq-IuY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class PlagaDetectorCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PlagaDetectorCNN, self).__init__()\n",
        "\n",
        "        # Capas convolucionales\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)  # Conv1: 3 canales de entrada, 32 canales de salida\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # Conv2: 32 canales de entrada, 64 de salida\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # Conv3: 64 canales de entrada, 128 de salida\n",
        "\n",
        "        # Capa de max-pooling\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # Tamaño del kernel 2x2\n",
        "\n",
        "        # Capas completamente conectadas\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)  # Capa densa (128x16x16 es la dimensión de salida de las convoluciones)\n",
        "        self.fc2 = nn.Linear(512, len(train_data.classes))  # La salida final tiene tantas clases como train_data.classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Aplicamos las convoluciones seguidas de ReLU y MaxPooling\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "\n",
        "        # Aplanamos la salida para pasarla a la capa totalmente conectada\n",
        "        x = x.view(-1, 128 * 16 * 16)  # Aplanar: las dimensiones deben coincidir con la capa fc1\n",
        "\n",
        "        # Capas completamente conectadas\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "nArZDdTC-Lfk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuración del Dispositivo (CPU o GPU)"
      ],
      "metadata": {
        "id": "dkH_BDo6-NbL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Suponiendo que train_data_full es el conjunto de datos completo ImageFolder\n",
        "train_data_full = datasets.ImageFolder(os.path.join(dataset_dir), transform=transform)\n",
        "\n",
        "# Obtener el número de clases\n",
        "num_classes = len(train_data_full.classes)\n",
        "\n",
        "# Definir el modelo usando el número de clases\n",
        "class PlagaDetectorCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(PlagaDetectorCNN, self).__init__()\n",
        "\n",
        "        # Capas convolucionales\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 512)\n",
        "        self.fc2 = nn.Linear(512, num_classes)  # Usar num_classes aquí\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = self.pool(torch.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 16 * 16)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Ahora crear el modelo con el número de clases correcto\n",
        "model = PlagaDetectorCNN(num_classes).to(device)\n"
      ],
      "metadata": {
        "id": "wAIHuj9g-O4M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definición de Funciones de Entrenamiento y Evaluación"
      ],
      "metadata": {
        "id": "CrSGxi5a-SJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define el criterio de pérdida y el optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Función para entrenar el modelo\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=10):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)  # Mover a GPU/CPU\n",
        "            optimizer.zero_grad()  # Limpiar gradientes previos\n",
        "            outputs = model(images)  # Obtener las predicciones del modelo\n",
        "            loss = criterion(outputs, labels)  # Calcular la pérdida\n",
        "            loss.backward()  # Calcular el gradiente\n",
        "            optimizer.step()  # Actualizar los parámetros\n",
        "            running_loss += loss.item()  # Acumular la pérdida de la época\n",
        "        # Promediar la pérdida de la época\n",
        "        print(f\"Epoch {epoch+1}, Pérdida promedio: {running_loss/len(train_loader)}\")\n",
        "\n",
        "# Función para evaluar el modelo en el conjunto de validación\n",
        "def evaluate_model(model, valid_loader):\n",
        "    model.eval()  # Modo evaluación (desactiva dropout, etc.)\n",
        "    total, correct = 0, 0\n",
        "    running_loss = 0.0\n",
        "    with torch.no_grad():  # No calcular gradientes durante la validación\n",
        "        for images, labels in valid_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)  # Obtener las predicciones del modelo\n",
        "            loss = criterion(outputs, labels)  # Calcular la pérdida de validación\n",
        "            running_loss += loss.item()  # Acumular la pérdida de validación\n",
        "            _, predicted = torch.max(outputs, 1)  # Obtener las predicciones (la clase con mayor probabilidad)\n",
        "            total += labels.size(0)  # Total de muestras\n",
        "            correct += (predicted == labels).sum().item()  # Comparar con las etiquetas reales\n",
        "\n",
        "    # Imprimir métricas\n",
        "    print(f\"Pérdida en validación: {running_loss/len(valid_loader)}\")\n",
        "    print(f\"Precisión en validación: {100 * correct / total}%\")\n"
      ],
      "metadata": {
        "id": "VmAEPV6D-UGh"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenamiento del Modelo\n"
      ],
      "metadata": {
        "id": "zLdhlxNa-YHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model, train_loader, criterion, optimizer, epochs=10)\n",
        "evaluate_model(model, valid_loader)\n",
        "\n"
      ],
      "metadata": {
        "id": "ieej0Tk__ACo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uso del Modelo para Predicciones\n"
      ],
      "metadata": {
        "id": "XfiGjp18_B4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def predict_image(image_path, model):\n",
        "    model.eval()  # Modo evaluación\n",
        "    # Transforma la imagen para que sea compatible con el modelo\n",
        "    transform = transforms.Compose([transforms.Resize((128, 128)), transforms.ToTensor()])\n",
        "    image = Image.open(image_path)  # Abre la imagen\n",
        "    image = transform(image).unsqueeze(0).to(device)  # Aplica las transformaciones y añade la dimensión de batch\n",
        "    output = model(image)  # Realiza la predicción\n",
        "    _, predicted = torch.max(output, 1)  # Obtén la clase con la mayor probabilidad\n",
        "    return train_data.classes[predicted.item()]  # Devuelve el nombre de la clase\n",
        "\n",
        "# Ruta de la imagen de prueba\n",
        "image_path = '/content/pathogen/test/image.jpg'  # Cambia este path por el correcto\n",
        "\n",
        "# Realiza la predicción\n",
        "prediccion = predict_image(image_path, model)\n",
        "print(f\"Plaga detectada: {prediccion}\")\n",
        "\n",
        "# Muestra la imagen junto con la predicción\n",
        "plt.imshow(Image.open(image_path))\n",
        "plt.title(f\"Predicción: {prediccion}\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "HU4Kwrr-_DTm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}